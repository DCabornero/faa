{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAA: Práctica 1\n",
    "\n",
    "### Autores: David Cabornero Pascual y Mario García Pascual\n",
    "\n",
    "## 0. Introducción\n",
    "\n",
    "La práctica 1 consiste en implementar en Python los elementos necesarios para poder manejar conjuntos de datos, estrategias de particionado y clasificadores. Después hay que probar que su funcionamiento es correcto, comparar los resultados con el de los métodos de scikit-learn, y por último ver la curva ROC de los clasificadores.\n",
    "\n",
    "Para solucionar el problema de que la última columna de los datos German no sea categórica hemos tenido que modificar la clase Datos. La modificación consiste en añadir el argumento opcional predNominal al constructor de Datos, que en caso de ser True fuerza a la última columna a ser de tipo nominal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Clasificador import Clasificador, ClasificadorNaiveBayes\n",
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple, ValidacionCruzada\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from astropy.table import QTable, Table, Column\n",
    "\n",
    "datosGerman = Datos('german.data',predNominal=True)\n",
    "datosTic = Datos('tic-tac-toe.data',predNominal=True)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "cll = ClasificadorNaiveBayes(laplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Particionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección comprobamos que funcionan correctamente las estrategias de particionado. Dado que la cantidad de datos es lo único que importa para realizar las particiones, probamos el funcionamiento sólo para German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showParticiones(val,datos):\n",
    "    val.creaParticiones(datos)\n",
    "    print('Número de particiones: ', len(val.particiones))\n",
    "    for i in range(len(val.particiones)):\n",
    "        print('Partición número ', i)\n",
    "        print('Número de índices del trainSet:')\n",
    "        print(len(val.particiones[i].indicesTrain))\n",
    "        print('Número de índices del testSet:')\n",
    "        print(len(val.particiones[i].indicesTest))\n",
    "        print()\n",
    "    # Vamos a probar a unir indicesTrain e indicesTest de una partición, ordenarlos\n",
    "    # e imprimirlos, para comprobar que salen todos los indices\n",
    "    print(sorted(val.particiones[0].indicesTest + val.particiones[0].indicesTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método showParticiones imprime el número de indices de Train y Test de cada partición, y después imprime el array ordenado resultante de unir las dos listas de índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particionado simple:\n",
      "Número de particiones:  10\n",
      "Partición número  0\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  1\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  2\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  3\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  4\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  5\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  6\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  7\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  8\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "Partición número  9\n",
      "Número de índices del trainSet:\n",
      "800\n",
      "Número de índices del testSet:\n",
      "200\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "\n",
      "\n",
      "\n",
      "Particionado cruzado:\n",
      "Número de particiones:  6\n",
      "Partición número  0\n",
      "Número de índices del trainSet:\n",
      "834\n",
      "Número de índices del testSet:\n",
      "166\n",
      "\n",
      "Partición número  1\n",
      "Número de índices del trainSet:\n",
      "834\n",
      "Número de índices del testSet:\n",
      "166\n",
      "\n",
      "Partición número  2\n",
      "Número de índices del trainSet:\n",
      "834\n",
      "Número de índices del testSet:\n",
      "166\n",
      "\n",
      "Partición número  3\n",
      "Número de índices del trainSet:\n",
      "834\n",
      "Número de índices del testSet:\n",
      "166\n",
      "\n",
      "Partición número  4\n",
      "Número de índices del trainSet:\n",
      "834\n",
      "Número de índices del testSet:\n",
      "166\n",
      "\n",
      "Partición número  5\n",
      "Número de índices del trainSet:\n",
      "830\n",
      "Número de índices del testSet:\n",
      "170\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
     ]
    }
   ],
   "source": [
    "propTest = 0.2 #Proporción de datos destinados al testSet\n",
    "numEx = 20 # Número de ejecuciones de la validación simple\n",
    "print('Particionado simple:')\n",
    "valS = ValidacionSimple(0.2,10)\n",
    "showParticiones(valS,datosGerman)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Particionado cruzado:')\n",
    "numP = 6 # Número de particiones de la validación cruzada\n",
    "valC = ValidacionCruzada(numP)\n",
    "showParticiones(valC, datosGerman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "German tiene 1000 datos. Hacemos la prueba de Validación Simple con una proporción de Test del 20% y 6 10 ejecuciones. Podemos ver que se imprimen 10 particiones con 800 índices de Train y 200 de Test respectivamente, y que la unión de las dos listas son todos los índices. Luego hacemos la prueba de Validación Cruzada con 6 particiones. Vemos que se imprimen 6 particiones con 834 de Train y 166 de Test, excepto la última que partición que tiene 830 y 170. 166 = floor(1000/6), y la última partición sale distinta para compensar que la división 1000/6 no sea exacta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación Simple separa el conjunto de datos en train y test, entrena con los datos de train y estima el error de generalización con datos test. En su lugar, Validación Cruzada separa el conjunto de datos en K bloques, y para cada uno de los bloques, entrena con los K-1 restantes y estima el error con el bloque. Las ventajas y desventajas son:\n",
    "* Validación Simple (con una ejecución) es computacionalmente menos costoso, pero a cambio desaprovecha algunos datos, que no llegan a usar para entrenar/testear en ningún momento.\n",
    "* Validación Cruzada es mucho más costoso, pero sí aprovecha todos los datos y permite estimar mejor el error de generalización tomando la media de los errores de cada partición\n",
    "\n",
    "Cuando añadimos varias ejecuciones a Validación Simple la diferencia entre ambos tipos de validación se reduce. Pongamos un ejemplo: val. simple con 20% de test y 5 ejecuciones y val. cruzada con 5 bloques. En ambos casos se obtendrían 5 particiones con aprox. 20% de test cada una. La diferencia es que las particiones obtenidas con val. simple son totalmente independientes, mientras que las de val. cruzada tienen interdependientes, pues lo bloques básicos se mantienen. En val. cruzada cada dato se utiliza K-1 veces para entrenamiento y 1 para test; en val. simple no tiene por qué ser así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive-Bayes\n",
    "\n",
    "Para aplicar la corrección de Laplace hay que poner el atributo opcional laplace a True en el constructor del clasificador Naive-Bayes. En el código del notebook, cl = Naive-Bayes sin corrección de Laplace, cll = Naive-Bayes con corrección de Laplace.\n",
    "\n",
    "Mostramos dos tablas para cada conjunto de datos, una para el error medio y otra para la desviación típica, con/sin Laplace y según la estrategia de particionado que se ha usado.\n",
    "\n",
    "Para conseguir que los datos obtenidos con validación cruzada y simple sean lo más comparables posibles, hemos decidido probar\n",
    "\n",
    "* Validación Simple con 20% de test y 5 ejecuciones,\n",
    "* Validación Cruzada con 5 particiones,\n",
    "\n",
    "de tal forma que en ambos casos se obtengan 5 particiones con 20% de test en cada una.\n",
    "\n",
    "### 2.1 German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de medias: \n",
      "\n",
      "Laplace Simple       Cruzada      \n",
      "------- ------ -------------------\n",
      "     No  0.318 0.30599999999999994\n",
      "     Sí  0.496               0.288\n",
      "\n",
      "\n",
      " Tabla de desviaciones típicas:\n",
      "\n",
      "Laplace        Simple             Cruzada       \n",
      "------- ------------------- --------------------\n",
      "     No  0.0988230742286436 0.059110066824526596\n",
      "     Sí 0.05370288632839024  0.03501428280002318\n"
     ]
    }
   ],
   "source": [
    "propTest = 0.2 #Proporción de datos destinados al testSet\n",
    "numEx = 5 # Número de ejecuciones de la validación simple\n",
    "valS = ValidacionSimple(propTest,numEx)\n",
    "\n",
    "# Validación Simple con y sin Laplace\n",
    "errSL = cll.validacion(valS,datosGerman)\n",
    "errS = cl.validacion(valS,datosGerman)\n",
    "\n",
    "numP = 5 # Número de ejecuciones de la validación cruzada\n",
    "valC = ValidacionCruzada(numP)\n",
    "\n",
    "# Validación Cruzada con y sin Laplace\n",
    "errCL = cll.validacion(valC,datosGerman)\n",
    "errC = cl.validacion(valC,datosGerman)\n",
    "\n",
    "print('Tabla de medias: \\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [np.mean(errS),np.mean(errSL)]\n",
    "cruzada = [np.mean(errC),np.mean(errCL)]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)\n",
    "\n",
    "print('\\n\\n Tabla de desviaciones típicas:\\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [np.std(errS),np.std(errSL)]\n",
    "cruzada = [np.std(errC),np.std(errCL)]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tic Tac Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de medias: \n",
      "\n",
      "Laplace        Simple            Cruzada      \n",
      "------- ------------------- ------------------\n",
      "     No 0.28272251308900526 0.3025638257677984\n",
      "     Sí  0.3225130890052356 0.3026124035191882\n",
      "\n",
      "\n",
      "Tabla de desviaciones típicas:\n",
      "\n",
      "Laplace        Simple              Cruzada       \n",
      "------- -------------------- --------------------\n",
      "     No 0.037316292526084725 0.033593939809924395\n",
      "     Sí 0.024467688891199834 0.020241694081128248\n"
     ]
    }
   ],
   "source": [
    "propTest = 0.2 #Proporción de datos destinados al testSet\n",
    "numEx = 5 # Número de ejecuciones de la validación simple\n",
    "valS = ValidacionSimple(propTest,numEx)\n",
    "\n",
    "# Validación Simple con y sin Laplace\n",
    "errSL = cll.validacion(valS,datosTic)\n",
    "errS = cl.validacion(valS,datosTic)\n",
    "\n",
    "numP = 5 # Número de particiones de la validación cruzada\n",
    "valC = ValidacionCruzada(numP)\n",
    "\n",
    "# Validación Cruzada con y sin Laplace\n",
    "errCL = cll.validacion(valC,datosTic)\n",
    "errC = cl.validacion(valC,datosTic)\n",
    "\n",
    "print('Tabla de medias: \\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [np.mean(errS),np.mean(errSL)]\n",
    "cruzada = [np.mean(errC),np.mean(errCL)]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)\n",
    "\n",
    "print('\\n\\nTabla de desviaciones típicas:\\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [np.std(errS),np.std(errSL)]\n",
    "cruzada = [np.std(errC),np.std(errCL)]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scikit-learn\n",
    "### 3. 1 German \n",
    "\n",
    "\n",
    "En la base de datos German aplicaremos el algoritmo de Naive-Bayes continuo, es decir, GaussianNB. Mientras que en tic-tac-toe todos los atributos son discretos, aquí sí que existen atributos continuos. Aunque Scikit-learn nos da herramientas para hacer validación cruzada, no existe un algoritmo para realizar más de una ejecución de validación simple. No será un gran problema, pero tenemos que ir haciendo manualmente cada una de las iteraciones.\n",
    "\n",
    "No aplicaremos Lagrange, ya que solo se aplica al caso discreto. Aunque aquí podemos observar que sale algo mejor la tasa de error respecto a nuestro algoritmo, debemos tener en cuenta que aquí sí que existen diferencias sustanciales. Aquí estamos aplicando la versión continua de Naive-Bayes a los atributos continuos y a los discretos y al parecer esto beneficia al algoritmo. De todas formas, queremos recalar que esto ocurre en este dataset en concreto, y en general es mejor usar el algoritmo correspondiente al tipo de atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de medias y desviaciones típicas de los errores: \n",
      "\n",
      "Parámetro        Simple              Cruzada      \n",
      "--------- -------------------- -------------------\n",
      "    Media                0.248               0.268\n",
      "D. Típica 0.019899748742132416 0.03264965543462904\n"
     ]
    }
   ],
   "source": [
    "propTest = 0.2 #Proporción de datos destinados al testSet\n",
    "numEx = 5 # Número de ejecuciones de la validación simple\n",
    "# Necesitamos separar atributos de la clasificación\n",
    "X, y = datosGerman.datos[:,:-1], datosGerman.datos[:,-1].astype('int')\n",
    "mult = GaussianNB()\n",
    "errS = []\n",
    "for _ in range(numEx):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=propTest)\n",
    "    mult.fit(X_train,y_train)\n",
    "    err = 1 - mult.score(X_test,y_test)\n",
    "    errS.append(err)\n",
    "\n",
    "meanS, stdS = np.mean(errS), np.std(errS)\n",
    "\n",
    "\n",
    "numP = 5 # Número de particiones de la validación cruzada\n",
    "\n",
    "# Validación Cruzada\n",
    "errC = 1 - cross_val_score(mult,X,y,cv=numP)\n",
    "meanC, stdC = np.mean(errC), np.std(errC)\n",
    "\n",
    "print('Tabla de medias y desviaciones típicas de los errores: \\n')\n",
    "param = ['Media','D. Típica']\n",
    "simple = [meanS,stdS]\n",
    "cruzada = [meanC,stdC]\n",
    "t = Table([param,simple,cruzada],names=['Parámetro','Simple','Cruzada'])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2 Tic Tac Toe \n",
    "\n",
    "Para el algoritmo Tic-Tac-Toe, todos los atributos son discretos. Por ello, aplicarmos el algoritmo de Scikit-Learn discreto, es decir, MultinomialNB. Mostraremos los resultados con y sin Lagrange (cuando no se aplica Lagrange ponemos un número muy cercano a 0, pero no 0 para evitar errores numéricos).\n",
    "\n",
    "También utilizaremos el algoritmo OneHotEncoder, que codifica los atributos discretos y ayuda a la hora de mejorar la eficiencia del programa. Sin embargo, en este caso Naive-Bayes no tiene en cuenta la diferencia entre los números que sirven de codificación. Por ello, no tiene sentido que este algoritmo mejore el error.\n",
    "\n",
    "Como vemos, la tasa de errores es parecida, aunque algo más constante en la version de Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de medias: \n",
      "\n",
      "Laplace        Simple            Cruzada      \n",
      "------- ------------------- ------------------\n",
      "     No  0.2958333333333333 0.3371727748691099\n",
      "     Sí 0.29791666666666666 0.3371727748691099\n",
      "\n",
      "\n",
      "Tabla de desviaciones típicas:\n",
      "\n",
      "Laplace        Simple              Cruzada      \n",
      "------- -------------------- -------------------\n",
      "     No 0.015590239111558104 0.05794563417312506\n",
      "     Sí 0.014129854131510996 0.05794563417312506\n"
     ]
    }
   ],
   "source": [
    "propTest = 0.2 #Proporción de datos destinados al testSet\n",
    "numEx = 5 # Número de ejecuciones de la validación simple\n",
    "# Necesitamos separar atributos de la clasificación\n",
    "X, y = datosTic.datos[:,:-1], datosTic.datos[:,-1].astype('int')\n",
    "#OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X_new = enc.fit_transform(X)\n",
    "\n",
    "multL = MultinomialNB() # Naive-Bayes con Lagrange\n",
    "mult = MultinomialNB(alpha=1.0e-10) #Naive-Bayes sin Lagrange, se aproxima a cero para evitar errores numéricos\n",
    "\n",
    "#Validación simple con Lagrange\n",
    "errSL = []\n",
    "for _ in range(numEx):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=propTest)\n",
    "    multL.fit(X_train,y_train)\n",
    "    err = 1 - multL.score(X_test,y_test)\n",
    "    errSL.append(err)\n",
    "\n",
    "meanSL, stdSL = np.mean(errSL), np.std(errSL)\n",
    "\n",
    "#Validación simple sin Lagrange\n",
    "errS = []\n",
    "for _ in range(numEx):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=propTest)\n",
    "    mult.fit(X_train,y_train)\n",
    "    err = 1 - mult.score(X_test,y_test)\n",
    "    errS.append(err)\n",
    "\n",
    "meanS, stdS = np.mean(errS), np.std(errS)\n",
    "\n",
    "numP = 5 # Número de particiones de la validación cruzada\n",
    "\n",
    "# Validación Cruzada con Lagrange\n",
    "errCL = 1 - cross_val_score(multL,X_new,y,cv=numP)\n",
    "meanCL, stdCL = np.mean(errCL), np.std(errCL)\n",
    "\n",
    "# Validación Cruzada sin Lagrange\n",
    "errC = 1 - cross_val_score(mult,X_new,y,cv=numEx)\n",
    "meanC, stdC = np.mean(errC), np.std(errC)\n",
    "\n",
    "#Tablas\n",
    "print('Tabla de medias: \\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [meanS,meanSL]\n",
    "cruzada = [meanC,meanCL]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)\n",
    "\n",
    "print('\\n\\nTabla de desviaciones típicas:\\n')\n",
    "laplace = ['No','Sí']\n",
    "simple = [stdS,stdSL]\n",
    "cruzada = [stdC,stdCL]\n",
    "t = Table([laplace,simple,cruzada],names=['Laplace','Simple','Cruzada'])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación de hipótesis mediante análisis ROC\n",
    "\n",
    "Para construir la matriz de confusión hemos implementado el método get_confusion_matrix(datos,proporcionTest) para la clase Clasificador, que devuelve la matriz de confusión del clasificador utilizando validación simple con la proporción de test dada. Una vez tenemos la matriz de confusión, la función show_roc_curve obtiene la tasa de verdaderos positivos y la tasa de falsos positivos y las grafica en el espacio ROC uniendo dicho punto con el (0,0) y (1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_roc_curve(conf_mat):\n",
    "    err = (conf_mat[0,1] + conf_mat[1,0])/np.sum(conf_mat)\n",
    "    print(conf_mat)\n",
    "    print(\"Tasa de error: \",err)\n",
    "    tpr = conf_mat[0,0] / np.sum(conf_mat[0])\n",
    "    fpr = conf_mat[1,0] / np.sum(conf_mat[1])\n",
    "    print(\"Tasa de verdaderos positivos (TPR): \",tpr)\n",
    "    print(\"Tasa de falsos positivos (FPR): \", fpr)\n",
    "    x = [0, fpr, 1]\n",
    "    y = [0, tpr, 1]\n",
    "    plt.plot(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curva ROC de tic-tac-toe\n",
      "[[156.  30.]\n",
      " [ 68.  33.]]\n",
      "Tasa de error:  0.34146341463414637\n",
      "Tasa de verdaderos positivos (TPR):  0.8387096774193549\n",
      "Tasa de falsos positivos (FPR):  0.6732673267326733\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d719d3748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curva ROC de german\n",
      "[[ 63.  20.]\n",
      " [120.  97.]]\n",
      "Tasa de error:  0.4666666666666667\n",
      "Tasa de verdaderos positivos (TPR):  0.7590361445783133\n",
      "Tasa de falsos positivos (FPR):  0.5529953917050692\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d719d3518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Muestra la curva ROC de tic-tac-toe\n",
    "datosGerman = Datos(\"german.data\",predNominal=True)\n",
    "cll = ClasificadorNaiveBayes(laplace=True)\n",
    "print(\"Curva ROC de tic-tac-toe\")\n",
    "conf_mat = cll.get_confusion_matrix(datosTic,proporcionTest=0.3)\n",
    "show_roc_curve(conf_mat)\n",
    "# Muestra la curva ROC de german\n",
    "print(\"Curva ROC de german\")\n",
    "conf_mat = cll.get_confusion_matrix(datosGerman,proporcionTest=0.3)\n",
    "show_roc_curve(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar validación simple con una sola ejecución las curvas ROC pueden cambiar sustancialmente entre ejecución y ejecución."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
